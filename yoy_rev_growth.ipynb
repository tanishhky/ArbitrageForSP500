{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def get_jsonparsed_data(url):\n",
    "    response = urlopen(url, cafile=certifi.where())\n",
    "    data = response.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "\n",
    "def get_quarterly_revenue(api_key: str, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch and process quarterly revenue data from Financial Modeling Prep API.\n",
    "    \n",
    "    Args:\n",
    "        api_key (str): Your FMP API key\n",
    "        symbol (str): Stock symbol\n",
    "        start_date (str): Start date in YYYY-MM-DD format\n",
    "        end_date (str): End date in YYYY-MM-DD format\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed quarterly revenue data with YoY growth\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct URL for FMP API\n",
    "\n",
    "    # url = (\"https://financialmodelingprep.com/api/v3/income-statement/AAPL?period=annual&limit=400&apikey=lhjT6XFmqVkPV78AlKyuNtip6aymeVgT\")\n",
    "    # print(url,get_jsonparsed_data(url))\n",
    "    \n",
    "    base_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{symbol}\"\n",
    "    url = (f\"{base_url}?period=annual&limit=400&apikey={api_key}\")\n",
    "    print(url)\n",
    "    res=get_jsonparsed_data(url)\n",
    "    print(res)\n",
    "    try:\n",
    "        # Fetch data\n",
    "        data = get_jsonparsed_data(url)\n",
    "        if not data:\n",
    "            return None\n",
    "            \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convert date column and set as index\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Filter date range\n",
    "        mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "        df = df[mask].copy()\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Extract quarter and year\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['year'] = df['date'].dt.year\n",
    "        \n",
    "        # Calculate YoY growth\n",
    "        df['revenue_yoy_growth'] = df.groupby('quarter')['revenue'].pct_change(4) * 100\n",
    "        \n",
    "        # Format results\n",
    "        result_df = df[[\n",
    "            'date', 'quarter', 'year', 'revenue', 'revenue_yoy_growth'\n",
    "        ]].copy()\n",
    "        \n",
    "        # Round numbers for better readability\n",
    "        result_df['revenue'] = result_df['revenue'].round(2)\n",
    "        result_df['revenue_yoy_growth'] = result_df['revenue_yoy_growth'].round(2)\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Your API key\n",
    "    API_KEY = \"lhjT6XFmqVkPV78AlKyuNtip6aymeVgT\"  # Replace with your actual API key if different\n",
    "    SYMBOL = \"AAPL\"\n",
    "    START_DATE = \"2015-03-31\"\n",
    "    END_DATE = \"2024-06-30\"\n",
    "    \n",
    "    results = get_quarterly_revenue(\n",
    "        api_key=API_KEY,\n",
    "        symbol=SYMBOL,\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE\n",
    "    )\n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    if results is not None:\n",
    "        # Display results\n",
    "        pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "        print(\"\\nQuarterly Revenue YoY Growth:\")\n",
    "        print(results.to_string(index=False))\n",
    "        \n",
    "        # Export to CSV\n",
    "        csv_filename = f\"{SYMBOL}_quarterly_revenue_growth.csv\"\n",
    "        results.to_csv(csv_filename, index=False)\n",
    "        print(f\"\\nResults saved to {csv_filename}\")\n",
    "        \n",
    "        # Display some summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(f\"Average YoY Growth: {results['revenue_yoy_growth'].mean():.2f}%\")\n",
    "        print(f\"Max YoY Growth: {results['revenue_yoy_growth'].max():.2f}%\")\n",
    "        print(f\"Min YoY Growth: {results['revenue_yoy_growth'].min():.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import certifi\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "WIKI_URL = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "SECTOR_DIR = \"sector_revenue_results\"\n",
    "\n",
    "# List of API keys to rotate between\n",
    "API_KEYS = [\"iq6DT26XPhKSubtLN7RUaavctUknriHy\", \"U2liplE4h7atJ1E9iAirE2cdCtxMi8Ve\", \"6wGoNRskPwA23aw0EMgWEN1JDRRVcY8M\"]\n",
    "CALL_LIMIT_PER_KEY = 200  # Each API key has a limit of 250 calls per day\n",
    "\n",
    "# Initialize counters for API key usage\n",
    "api_call_counters = [0] * len(API_KEYS)\n",
    "current_key_index = 0\n",
    "\n",
    "def get_current_api_key():\n",
    "    global current_key_index\n",
    "    global api_call_counters\n",
    "    \n",
    "    # Rotate to the next API key if the current one reaches its limit\n",
    "    if api_call_counters[current_key_index] >= CALL_LIMIT_PER_KEY:\n",
    "        current_key_index = (current_key_index + 1) % len(API_KEYS)\n",
    "    \n",
    "    # Increment the call counter for the current key\n",
    "    api_call_counters[current_key_index] += 1\n",
    "    \n",
    "    # Return the current API key\n",
    "    return API_KEYS[current_key_index]\n",
    "\n",
    "def scrape_wikipedia_sp500():\n",
    "    \"\"\"Scrape S&P 500 companies and their sectors from Wikipedia.\"\"\"\n",
    "    response = requests.get(WIKI_URL)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    rows = table.find_all('tr')[1:]  # Skip header row\n",
    "    \n",
    "    companies_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        ticker = cols[0].text.strip()\n",
    "        company_name = cols[1].text.strip()\n",
    "        sector = cols[3].text.strip()\n",
    "        companies_data.append((ticker, company_name, sector))\n",
    "    \n",
    "    return companies_data\n",
    "\n",
    "def get_jsonparsed_data(url):\n",
    "    response = urlopen(url, cafile=certifi.where())\n",
    "    data = response.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "\n",
    "def get_quarterly_revenue(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch and process quarterly revenue data from Financial Modeling Prep API.\n",
    "    \"\"\"\n",
    "    api_key = get_current_api_key()  # Get the current API key\n",
    "    base_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{symbol}\"\n",
    "    url = f\"{base_url}?period=annual&limit=400&apikey={api_key}\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        data = get_jsonparsed_data(url)\n",
    "        if not data:\n",
    "            return None\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convert date column and set as index\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Filter date range\n",
    "        mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "        df = df[mask].copy()\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Extract quarter and year\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['year'] = df['date'].dt.year\n",
    "        \n",
    "        # Calculate YoY growth\n",
    "        df['revenue_yoy_growth'] = df.groupby('quarter')['revenue'].pct_change(4) * 100\n",
    "        \n",
    "        # Format results\n",
    "        result_df = df[['date', 'quarter', 'year', 'revenue', 'revenue_yoy_growth']].copy()\n",
    "        result_df['revenue'] = result_df['revenue'].round(2)\n",
    "        result_df['revenue_yoy_growth'] = result_df['revenue_yoy_growth'].round(2)\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_sector_revenue(sector, companies, start_date, end_date):\n",
    "    \"\"\"Process revenue data for companies in a given sector and save it.\"\"\"\n",
    "    sector_file = os.path.join(SECTOR_DIR, f\"{sector}_revenue.csv\")\n",
    "    \n",
    "    for ticker, company_name in companies:\n",
    "        print(f\"Processing {ticker} ({company_name}) in sector {sector}...\")\n",
    "        company_revenue_df = get_quarterly_revenue(ticker, start_date, end_date)\n",
    "        \n",
    "        if company_revenue_df is not None:\n",
    "            company_revenue_df['ticker'] = ticker\n",
    "            company_revenue_df['company_name'] = company_name\n",
    "            \n",
    "            # Save the company data as soon as processed\n",
    "            if not os.path.exists(sector_file):\n",
    "                company_revenue_df.to_csv(sector_file, index=False, mode='w', header=True)\n",
    "            else:\n",
    "                company_revenue_df.to_csv(sector_file, index=False, mode='a', header=False)\n",
    "                \n",
    "            print(f\"Saved revenue data for {ticker} to {sector_file}\")\n",
    "        else:\n",
    "            print(f\"No data found for {ticker}.\")\n",
    "\n",
    "def main():\n",
    "    os.makedirs(SECTOR_DIR, exist_ok=True)\n",
    "    \n",
    "    # Scrape SP500 companies and their sectors\n",
    "    companies_data = scrape_wikipedia_sp500()\n",
    "    \n",
    "    # Group companies by sector\n",
    "    sectors = {}\n",
    "    for ticker, company_name, sector in companies_data:\n",
    "        if sector not in sectors:\n",
    "            sectors[sector] = []\n",
    "        sectors[sector].append((ticker, company_name))\n",
    "    \n",
    "    # Define start and end dates for revenue data\n",
    "    start_date = \"2015-01-01\"\n",
    "    end_date = \"2024-06-30\"\n",
    "    \n",
    "    # Process each sector\n",
    "    for sector, companies in sectors.items():\n",
    "        print(f\"\\nProcessing sector: {sector}\")\n",
    "        process_sector_revenue(sector, companies, start_date, end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
