{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_csv(file):\n",
    "    # Extract the ticker from the filename\n",
    "    ticker = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(file, parse_dates=['Date'])\n",
    "    \n",
    "    # Ensure the data is sorted by Date\n",
    "    df = df.sort_values(by='Date')\n",
    "    \n",
    "    # Select relevant columns (You can change 'Revenue Growth' to any other metric you're analyzing)\n",
    "    df['Revenue Growth'] = df['Revenue Growth']\n",
    "    \n",
    "    # Calculate quarterly YoY growth (4 quarters = 1 year, hence use .pct_change(4))\n",
    "    df['YoY_Growth'] = df['Revenue Growth'].pct_change(4) * 100\n",
    "    \n",
    "    # Keep only the Date and YoY growth, and rename for identification\n",
    "    df = df[['Date', 'YoY_Growth']].copy()\n",
    "    df.rename(columns={'YoY_Growth': ticker + '_YoY_Growth'}, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory where your CSV files are stored\n",
    "csv_directory = 'SP425CSVs/'\n",
    "\n",
    "# Use glob to find all the CSV files\n",
    "csv_files = glob.glob(os.path.join(csv_directory, '*_data_with_metrics.csv'))\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file and process it\n",
    "for file in csv_files:\n",
    "    df = load_and_process_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all dataframes on 'Date' column\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on='Date', how='outer')\n",
    "\n",
    "# Drop rows with NaN values (optional, or you can fillna if needed)\n",
    "merged_df = merged_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation matrix\n",
    "correlation_matrix = merged_df.set_index('Date').corr(method='pearson')\n",
    "\n",
    "# Alternatively, you can use spearman: merged_df.set_index('Date').corr(method='spearman')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Company YoY Growth Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the CSV files are stored\n",
    "data_directory = 'SP425CSVs/'\n",
    "\n",
    "# Load all CSV files with the format {ticker}_data_with_metrics.csv\n",
    "all_files = glob.glob(os.path.join(data_directory, \"*_data_with_metrics.csv\"))\n",
    "\n",
    "# Create a dictionary to store data for each company\n",
    "company_data = {}\n",
    "\n",
    "for file in all_files:\n",
    "    ticker = os.path.basename(file).split('_')[0]  # Extract ticker from filename\n",
    "    df = pd.read_csv(file, parse_dates=['Date'])\n",
    "    \n",
    "    # Ensure the data is sorted by date\n",
    "    df = df.sort_values(by='Date')\n",
    "    \n",
    "    # Add to the dictionary\n",
    "    company_data[ticker] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate YoY Growth, modified to check for missing columns\n",
    "def calculate_yoy_growth(df, metric):\n",
    "    # Ensure 'Date' is a datetime object\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with invalid dates\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "    # Check if the metric exists in the dataframe\n",
    "    if metric not in df.columns:\n",
    "        print(f\"Metric '{metric}' not found in data for this company.\")\n",
    "        return pd.Series()  # Return an empty series if the metric is not found\n",
    "\n",
    "    # Set 'Date' as the index\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Resample the data by quarter\n",
    "    df_quarterly = df.resample('Q')[metric].sum()\n",
    "\n",
    "    # Calculate YoY growth\n",
    "    df_quarterly_yoy = df_quarterly.pct_change(4) * 100\n",
    "\n",
    "    return df_quarterly_yoy\n",
    "\n",
    "# Analyze metrics\n",
    "metrics_to_analyze = ['Revenue Growth', 'P/E Ratio', 'ROE', 'Debt-to-Equity Ratio']\n",
    "company_growth_data = {}\n",
    "\n",
    "for ticker, df in company_data.items():\n",
    "    company_growth_data[ticker] = {}\n",
    "    \n",
    "    for metric in metrics_to_analyze:\n",
    "        yoy_growth = calculate_yoy_growth(df, metric)\n",
    "        \n",
    "        # Only add the result if it's not empty\n",
    "        if not yoy_growth.empty:\n",
    "            company_growth_data[ticker][metric] = yoy_growth\n",
    "\n",
    "# Combine YoY growth data into a single DataFrame for correlation analysis\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for ticker, growth_metrics in company_growth_data.items():\n",
    "    for metric in metrics_to_analyze:\n",
    "        # Check if the metric has been calculated for the company\n",
    "        if metric in growth_metrics:\n",
    "            combined_df[f'{ticker}_{metric}'] = growth_metrics[metric]\n",
    "\n",
    "# Drop rows with missing values\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "# Perform further analysis (e.g., correlation analysis) on combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine YoY growth data into a single DataFrame for correlation analysis\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for ticker, growth_metrics in company_growth_data.items():\n",
    "    for metric in metrics_to_analyze:\n",
    "        combined_df[f'{ticker}_{metric}'] = growth_metrics[metric]\n",
    "\n",
    "# Drop rows with missing values (NaN)\n",
    "combined_df = combined_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for each metric\n",
    "for metric in metrics_to_analyze:\n",
    "    relevant_columns = [col for col in combined_df.columns if metric in col]\n",
    "    \n",
    "    # Create a correlation matrix for this metric\n",
    "    correlation_matrix = combined_df[relevant_columns].corr()\n",
    "\n",
    "    # Plot the correlation matrix as a heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title(f'Correlation Matrix for {metric}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_sp500_sectors():\n",
    "    sp500 = yf.Ticker(\"^GSPC\")\n",
    "    return sp500.info.get('sector', [])\n",
    "\n",
    "def get_sector_companies(sector):\n",
    "    tickers = yf.Ticker(\"^SP500-\" + sector.upper())\n",
    "    return list(tickers.info.get('components', []))\n",
    "\n",
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "def calculate_quarterly_yoy_growth(data):\n",
    "    quarterly_data = data['Close'].resample('Q').last()\n",
    "    yoy_growth = quarterly_data.pct_change(periods=4)\n",
    "    return yoy_growth\n",
    "\n",
    "def process_company(ticker, start_date, end_date):\n",
    "    try:\n",
    "        stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "        quarterly_yoy_growth = calculate_quarterly_yoy_growth(stock_data)\n",
    "        return quarterly_yoy_growth\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_sector(sector, start_date, end_date):\n",
    "    companies = get_sector_companies(sector)\n",
    "    if len(companies) <= 3:\n",
    "        print(f\"Skipping {sector} sector: Only {len(companies)} companies found.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Processing {sector} sector ({len(companies)} companies)...\")\n",
    "    results = {}\n",
    "    for ticker in companies:\n",
    "        print(f\"  Processing {ticker}...\")\n",
    "        result = process_company(ticker, start_date, end_date)\n",
    "        if result is not None:\n",
    "            results[ticker] = result\n",
    "        time.sleep(1)  # To avoid hitting API rate limits\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No valid results for {sector} sector.\")\n",
    "        return None\n",
    "\n",
    "    combined_results = pd.concat(results, axis=1)\n",
    "    combined_results.columns = pd.MultiIndex.from_tuples(combined_results.columns)\n",
    "    return combined_results\n",
    "\n",
    "def main():\n",
    "    # Calculate the date range for the past 20 years\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365.25 * 20)\n",
    "\n",
    "    # Get all S&P 500 sectors\n",
    "    sectors = get_sp500_sectors()\n",
    "\n",
    "    # Create a directory for output files\n",
    "    output_dir = \"sector_growth_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each sector\n",
    "    for sector in sectors:\n",
    "        sector_results = process_sector(sector, start_date, end_date)\n",
    "        if sector_results is not None:\n",
    "            # Save results to CSV\n",
    "            csv_filename = os.path.join(output_dir, f\"{sector}_quarterly_yoy_growth.csv\")\n",
    "            sector_results.to_csv(csv_filename)\n",
    "            print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "            # Display summary statistics\n",
    "            print(\"\\nSummary Statistics:\")\n",
    "            print(sector_results.mean().sort_values(ascending=False))\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"All sectors processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_sp500_sectors():\n",
    "    sp500 = yf.Ticker(\"^GSPC\")\n",
    "    return sp500.info.get('sector', [])\n",
    "\n",
    "def get_sector_companies(sector):\n",
    "    tickers = yf.Ticker(\"^SP500-\" + sector.upper())\n",
    "    return list(tickers.info.get('components', []))\n",
    "\n",
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(start=start_date, end=end_date)\n",
    "    return data\n",
    "\n",
    "def calculate_quarterly_yoy_growth(data):\n",
    "    if data.empty:\n",
    "        return None\n",
    "    quarterly_data = data['Close'].resample('Q').last()\n",
    "    yoy_growth = quarterly_data.pct_change(periods=4)\n",
    "    return yoy_growth\n",
    "\n",
    "def process_company(ticker, start_date, end_date):\n",
    "    try:\n",
    "        stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "        quarterly_yoy_growth = calculate_quarterly_yoy_growth(stock_data)\n",
    "        return quarterly_yoy_growth\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_sector(sector, start_date, end_date):\n",
    "    companies = get_sector_companies(sector)\n",
    "    if len(companies) <= 3:\n",
    "        print(f\"Skipping {sector} sector: Only {len(companies)} companies found.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Processing {sector} sector ({len(companies)} companies)...\")\n",
    "    results = {}\n",
    "    for ticker in companies:\n",
    "        print(f\"  Processing {ticker}...\")\n",
    "        result = process_company(ticker, start_date, end_date)\n",
    "        if result is not None and not result.empty:\n",
    "            results[ticker] = result\n",
    "        time.sleep(1)  # To avoid hitting API rate limits\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No valid results for {sector} sector.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        combined_results = pd.concat(results, axis=1)\n",
    "        combined_results.columns = pd.MultiIndex.from_tuples(combined_results.columns)\n",
    "        return combined_results\n",
    "    except ValueError as e:\n",
    "        print(f\"Error combining results for {sector} sector: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Calculate the date range for the past 20 years\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365.25 * 20)\n",
    "\n",
    "    # Get all S&P 500 sectors\n",
    "    sectors = get_sp500_sectors()\n",
    "\n",
    "    # Create a directory for output files\n",
    "    output_dir = \"sector_growth_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each sector\n",
    "    for sector in sectors:\n",
    "        sector_results = process_sector(sector, start_date, end_date)\n",
    "        if sector_results is not None:\n",
    "            # Save results to CSV\n",
    "            csv_filename = os.path.join(output_dir, f\"{sector}_quarterly_yoy_growth.csv\")\n",
    "            sector_results.to_csv(csv_filename)\n",
    "            print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "            # Display summary statistics\n",
    "            print(\"\\nSummary Statistics:\")\n",
    "            print(sector_results.mean().sort_values(ascending=False))\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        else:\n",
    "            print(f\"No results to save for {sector} sector.\")\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"All sectors processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
